# MapReduce

- Distributes the `processing of data` across the hadoop cluster
- Divides the data into partitions
  - Partitions are `mapped` (transformed) with a `mapper function`
  - Partitions are `reduced` (aggregated) with a `reducer function`
- It's resilient to failure
